{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC feature extraction and Network training\n",
    "\n",
    "In this notebook you will go through an example flow of processing audio data, complete with feature extraction and training.\n",
    "\n",
    "Make sure you read the instructions on the exercise sheet and follow the task order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as sps\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "DataSetPath = os.path.join(\"..\", \"..\", \"..\", \"Data\", \"hey_snips_kws_4.0\", \"hey_snips_research_6k_en_train_eval_clean_ter/\")\n",
    "\n",
    "with open(DataSetPath+\"train.json\") as jsonfile:\n",
    "    traindata = json.load(jsonfile)\n",
    "\n",
    "with open(DataSetPath+\"test.json\") as jsonfile:\n",
    "    testdata = json.load(jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_wav(old_fs, new_fs, data):\n",
    "    number_new_samples = int(data.shape[0] * float(new_fs)/float(old_fs))\n",
    "    data = sps.resample(data, number_new_samples)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    x_train_list = []\n",
    "    y_train_list = []\n",
    "\n",
    "    x_test_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    totalSliceLength = 10 # Length to stuff the signals to, given in seconds\n",
    "\n",
    "    # trainsize = len(traindata) # Number of loaded training samples\n",
    "    # testsize = len(testdata) # Number of loaded testing samples\n",
    "\n",
    "    trainsize = 1000 # Number of loaded training samples\n",
    "    testsize = 100 # Number of loaded testing samples\n",
    "\n",
    "\n",
    "    old_fs = 16000 # Sampling rate of the samples\n",
    "    new_fs = 9524 # Resampling rate\n",
    "    segmentLength = 1024 # Number of samples to use per segment\n",
    "\n",
    "    sliceLength = int(totalSliceLength * new_fs / segmentLength)*segmentLength\n",
    "\n",
    "    print(\"Num amplitudes per sample {}\".format(sliceLength))\n",
    "    print(\"Num non overlapping windows {}\".format(int(totalSliceLength * new_fs / segmentLength)))\n",
    "\n",
    "    for i in tqdm(range(trainsize)): \n",
    "        fs, train_sound_data = wavfile.read(DataSetPath+traindata[i]['audio_file_path']) # Read wavfile to extract amplitudes\n",
    "\n",
    "        x_train = train_sound_data.copy() # Get a mutable copy of the wavfile\n",
    "\n",
    "        _x_train = resample_wav(old_fs, new_fs, x_train)\n",
    "\n",
    "        _x_train.resize(sliceLength) # Zero stuff the single to a length of sliceLength\n",
    "        _x_train = _x_train.reshape(-1,int(segmentLength)) # Split slice into Segments with 0 overlap\n",
    "        x_train_list.append(_x_train.astype(np.float32)) # Add segmented slice to training sample list, cast to float so librosa doesn't complain\n",
    "        y_train_list.append(traindata[i]['is_hotword']) # Read label \n",
    "\n",
    "    for i in tqdm(range(testsize)):\n",
    "        fs, test_sound_data = wavfile.read(DataSetPath+testdata[i]['audio_file_path'])\n",
    "        x_test = test_sound_data.copy()\n",
    "        _x_test = resample_wav(old_fs, new_fs, x_test)\n",
    "        _x_test.resize(sliceLength)\n",
    "        _x_test = _x_test.reshape((-1,int(segmentLength)))\n",
    "        x_test_list.append(_x_test.astype(np.float32))\n",
    "        y_test_list.append(testdata[i]['is_hotword'])\n",
    "\n",
    "    x_train = tf.convert_to_tensor(np.asarray(x_train_list))\n",
    "    y_train = tf.convert_to_tensor(np.asarray(y_train_list))\n",
    "\n",
    "    x_test = tf.convert_to_tensor(np.asarray(x_test_list))\n",
    "    y_test = tf.convert_to_tensor(np.asarray(y_test_list))\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mfccs(tensor):\n",
    "    sample_rate = 9524.0\n",
    "    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 4700.0, 64\n",
    "    frame_length = 1024\n",
    "    num_mfcc = 13\n",
    "\n",
    "    stfts = tf.signal.stft(tensor, frame_length=frame_length, frame_step=frame_length, fft_length=frame_length) \n",
    "    spectrograms = tf.abs(stfts)\n",
    "    spectrograms = tf.reshape(spectrograms, (spectrograms.shape[0],spectrograms.shape[1],-1))\n",
    "    num_spectrogram_bins = stfts.shape[-1]\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "      num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz,\n",
    "      upper_edge_hertz)\n",
    "    mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :num_mfcc]\n",
    "    return tf.reshape(mfccs, (mfccs.shape[0],mfccs.shape[1],mfccs.shape[2],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|▏         | 13/1000 [00:00<00:07, 124.95it/s]Num amplitudes per sample 95232\n",
      "Num non overlapping windows 93\n",
      "100%|██████████| 1000/1000 [00:09<00:00, 111.00it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 121.97it/s]\n",
      "(1000, 93, 1024)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = load_data()\n",
    "\n",
    "import pickle\n",
    "PATHTODUMP = os.path.join(\"..\", \"..\", \"..\", \"Data\", \"x_train.txt\")\n",
    "with open(PATHTODUMP, 'wb') as f:\n",
    "    pickle.dump(x_train, f)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[[[ 5.88103600e+01]\n   [ 1.37720597e+00]\n   [ 2.82561827e+00]\n   ...\n   [ 4.41661716e-01]\n   [ 2.25466833e-01]\n   [-1.23737149e-01]]\n\n  [[ 5.87619247e+01]\n   [ 1.28692973e+00]\n   [ 3.07473254e+00]\n   ...\n   [-1.23251885e-01]\n   [-7.68559217e-01]\n   [-7.26670146e-01]]\n\n  [[ 5.83584709e+01]\n   [ 7.62358189e-01]\n   [ 3.13854146e+00]\n   ...\n   [-1.49783000e-01]\n   [-2.27150857e-01]\n   [-4.61951375e-01]]\n\n  ...\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]]\n\n\n [[[ 5.33574066e+01]\n   [ 1.05985247e-01]\n   [ 1.95768321e+00]\n   ...\n   [-1.24322343e+00]\n   [-1.05255461e+00]\n   [-8.85908008e-01]]\n\n  [[ 5.47134438e+01]\n   [ 6.52908683e-01]\n   [ 1.59203970e+00]\n   ...\n   [-3.30422185e-02]\n   [-2.43753091e-01]\n   [ 1.79736078e-01]]\n\n  [[ 5.57675171e+01]\n   [ 9.82342064e-01]\n   [ 2.34199929e+00]\n   ...\n   [-8.12323749e-01]\n   [-3.93464833e-01]\n   [-6.57281935e-01]]\n\n  ...\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]]\n\n\n [[[ 5.28276863e+01]\n   [ 1.05818105e+00]\n   [ 2.47143245e+00]\n   ...\n   [-1.79673359e-01]\n   [-5.23830593e-01]\n   [-6.54091597e-01]]\n\n  [[ 5.24360428e+01]\n   [ 6.10394254e-02]\n   [ 1.91413379e+00]\n   ...\n   [-2.35452712e-01]\n   [-1.59693565e-02]\n   [-5.76865003e-02]]\n\n  [[ 5.16453056e+01]\n   [ 2.55511731e-01]\n   [ 1.95410299e+00]\n   ...\n   [-4.73675102e-01]\n   [-5.25128245e-01]\n   [-4.59162056e-01]]\n\n  ...\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]]\n\n\n ...\n\n\n [[[ 8.80475006e+01]\n   [-1.10664787e+01]\n   [ 3.94867921e+00]\n   ...\n   [ 4.28276360e-01]\n   [-1.15510851e-01]\n   [-1.02727365e+00]]\n\n  [[ 8.50572433e+01]\n   [-7.80441582e-01]\n   [ 5.64829931e-02]\n   ...\n   [ 1.96949017e+00]\n   [-1.80713888e-02]\n   [-2.36928880e-01]]\n\n  [[ 8.30409775e+01]\n   [-1.95106244e+00]\n   [-1.69205809e+00]\n   ...\n   [ 3.55705440e-01]\n   [-1.12802231e+00]\n   [ 7.37486243e-01]]\n\n  ...\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]]\n\n\n [[[ 7.35430222e+01]\n   [-4.76950586e-01]\n   [ 6.94962323e-01]\n   ...\n   [ 2.39201829e-01]\n   [ 7.67381966e-01]\n   [ 2.70064414e-01]]\n\n  [[ 1.02967407e+02]\n   [-1.24394474e+01]\n   [-1.74567306e+00]\n   ...\n   [ 4.98332530e-01]\n   [ 3.27293545e-01]\n   [-7.84424722e-01]]\n\n  [[ 1.03017197e+02]\n   [-5.79861307e+00]\n   [-2.56249976e+00]\n   ...\n   [ 2.20470071e+00]\n   [-1.34451258e+00]\n   [-3.98937196e-01]]\n\n  ...\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]]\n\n\n [[[ 7.51230774e+01]\n   [-8.63769114e-01]\n   [-6.74705058e-02]\n   ...\n   [ 9.59564447e-02]\n   [-7.80545324e-02]\n   [ 2.10900679e-01]]\n\n  [[ 7.42113495e+01]\n   [-5.29292583e-01]\n   [ 1.74981594e+00]\n   ...\n   [-1.73343733e-01]\n   [-2.35106245e-01]\n   [-2.63203323e-01]]\n\n  [[ 7.31611633e+01]\n   [-4.44530129e-01]\n   [ 7.16383874e-01]\n   ...\n   [-6.29308641e-01]\n   [-1.97776780e-01]\n   [-3.51597697e-01]]\n\n  ...\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]\n\n  [[-1.56304657e+02]\n   [-1.68587391e-07]\n   [ 0.00000000e+00]\n   ...\n   [ 0.00000000e+00]\n   [-1.01152432e-06]\n   [ 0.00000000e+00]]]], shape=(1000, 93, 13, 1), dtype=float32)\n(100, 93, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_mfcc = compute_mfccs(x_train)\n",
    "x_test_mfcc = compute_mfccs(x_test)\n",
    "\n",
    "\n",
    "\n",
    "print(x_train_mfcc)\n",
    "print(x_test_mfcc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(153.41629, shape=(), dtype=float32)\ntf.Tensor(-156.30466, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(x_train_mfcc))\n",
    "print(tf.reduce_min(x_train_mfcc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 10\n",
    "epochs = 10\n",
    "\n",
    "train_set = (x_train_mfcc/512 + 0.5)\n",
    "train_labels = y_train\n",
    "\n",
    "test_set = (x_test_mfcc/512 + 0.5)\n",
    "test_labels = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "90/90 [==============================] - 19s 200ms/step - loss: 0.3089 - accuracy: 0.8893 - val_loss: 0.3428 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 25s 277ms/step - loss: 0.1377 - accuracy: 0.9437 - val_loss: 0.4224 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 22s 248ms/step - loss: 0.1100 - accuracy: 0.9610 - val_loss: 0.5618 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 18s 204ms/step - loss: 0.0894 - accuracy: 0.9548 - val_loss: 0.9956 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 19s 211ms/step - loss: 0.0845 - accuracy: 0.9689 - val_loss: 1.1830 - val_accuracy: 0.0400\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 27s 300ms/step - loss: 0.0729 - accuracy: 0.9786 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 26s 295ms/step - loss: 0.0525 - accuracy: 0.9847 - val_loss: 1.2591 - val_accuracy: 0.1600\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 23s 260ms/step - loss: 0.0602 - accuracy: 0.9768 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 23s 251ms/step - loss: 0.0437 - accuracy: 0.9835 - val_loss: 0.2732 - val_accuracy: 0.8600\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 29s 324ms/step - loss: 0.0474 - accuracy: 0.9877 - val_loss: 0.0609 - val_accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#model.add(layers.InputLayer(input_shape=(train_set.shape[1],train_set.shape[2],train_set.shape[3]), batch_size=(batchSize)))\n",
    "model.add(layers.Conv2D(filters=3,kernel_size=(3,3),padding=\"same\",input_shape=(train_set[0].shape)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv2D(filters=16,kernel_size=(3,3),strides=(2,2),padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=32,kernel_size=(3,3),strides=(2,2),padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=48,kernel_size=(3,3),padding='same',strides=(2,2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(8, kernel_regularizer=(regularizers.l1(0))))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Dense(2))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "history = model.fit(train_set, y_train, batchSize, epochs, validation_split=0.1, workers=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 93, 13, 3)         30        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 93, 13, 3)         12        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 93, 13, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 7, 16)         448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 47, 7, 16)         64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 47, 7, 16)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 23, 3, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 2, 32)         4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 2, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 12, 2, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 1, 48)          13872     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 1, 48)          192       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 1, 48)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 392       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 19,796\n",
      "Trainable params: 19,598\n",
      "Non-trainable params: 198\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0599 - accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "score = model.evaluate(test_set, y_test)"
   ]
  },
  {
   "source": [
    "### Task 4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNUM = 1\n",
    "model.save(os.path.join(\"..\", \"Models\", \"MFCCmodel{:02d}.h5\".format(MODELNUM)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFLite conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpke28qgwn/assets\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "29192"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "train_set = train_set.numpy()\n",
    "test_set = test_set.numpy()\n",
    "train_labels = train_labels.numpy()\n",
    "test_labels = test_labels.numpy()\n",
    "tflite_model_name = 'MFCC'\n",
    "windows_per_sample = int(10 * 9524.0 / 1024)\n",
    "# Convert Keras model to a tflite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "quantize = True\n",
    "if (quantize):\n",
    "    def representative_dataset():\n",
    "        for i in range(500):\n",
    "            yield([train_set[i].reshape(1,windows_per_sample,13,1)])\n",
    "    # Set the optimization flag.\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # Enforce full-int8 quantization\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "    # Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(tflite_model_name + '.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "    c_str = ''\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # Add array length at top of file\n",
    "    c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data) :\n",
    "\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model_name = 'MFCC'\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model, c_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "== Input details ==\nname: conv2d_input_int8\nshape: [  1 156  13   1]\ntype: <class 'numpy.int8'>\n\n== Output details ==\nname: Identity_int8\nshape: [1 2]\ntype: <class 'numpy.int8'>\n"
     ]
    }
   ],
   "source": [
    "tflite_interpreter = tf.lite.Interpreter(model_path=tflite_model_name + '.tflite')\n",
    "tflite_interpreter.allocate_tensors()\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.003246503183618188, -128)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "input_details[0][\"quantization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros((len(test_set),), dtype=int)\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "for i in range(len(test_set)):\n",
    "    val_batch = test_set[i]\n",
    "    val_batch = val_batch / input_scale + input_zero_point\n",
    "    val_batch = np.expand_dims(val_batch, axis=0).astype(input_details[0][\"dtype\"])\n",
    "    tflite_interpreter.set_tensor(input_details[0]['index'], val_batch)\n",
    "    tflite_interpreter.allocate_tensors()\n",
    "    tflite_interpreter.invoke()\n",
    "\n",
    "    tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    #print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "    output = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    predictions[i] = output.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of quantized to int8 model is 100.0%\nCompared to float32 accuracy of 98.00000190734863%\nWe have a change of 1.9999980926513672%\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i] == test_labels[i]):\n",
    "        sum = sum + 1\n",
    "accuracy_score = sum / 100\n",
    "print(\"Accuracy of quantized to int8 model is {}%\".format(accuracy_score*100))\n",
    "print(\"Compared to float32 accuracy of {}%\".format(score[1]*100))\n",
    "print(\"We have a change of {}%\".format((accuracy_score-score[1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python371064bitmlomclab2conda13886544da5d4eb2a26bf924ee48306c",
   "display_name": "Python 3.7.10 64-bit ('mlomc_lab2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "747d9c539a0ab7e30c1319cda73980c9fb6a6fbd7c722a0c9aa95dd89f1d1480"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}